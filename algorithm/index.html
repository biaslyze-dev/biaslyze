
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="The NLP Bias Identification Toolkit">
      
      
      
        <link rel="canonical" href="https://biaslyze.org/algorithm/">
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../faq/">
      
      
      <link rel="icon" href="../resources/biaslyze_logo_favicon.png">
      <meta name="generator" content="mkdocs-1.5.2, mkdocs-material-9.2.8">
    
    
      
        <title>The Algorithm - Biaslyze</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.046329b4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.85d0ee34.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  <script
  defer
  data-domain="biaslyze.org"
  src="https://plausible.io/js/plausible.js"
></script>

<script>
  window.plausible = window.plausible || function () { (window.plausible.q = window.plausible.q || []).push(arguments) };

  /* Register event handlers after documented loaded */
  document.addEventListener("DOMContentLoaded", function () {
    /* Set up search tracking */
    if (document.forms.search) {
      var query = document.forms.search.query;
      query.addEventListener("blur", function() {
        if (this.value) plausible("Search", { props: { search_term: this.value } });
      })
    }

    /* Set up feedback, i.e. "Was this page helpful?" */
    document$.subscribe(function () {
      var feedback = document.forms.feedback;
      if (typeof feedback === "undefined") return;

      /* Send feedback to Plausible */
      for (var button of feedback.querySelectorAll("[type=submit]")) {
        button.addEventListener("click", function (ev) {
          ev.preventDefault();

          var page = document.location.pathname;
          var value = this.getAttribute("data-md-value");
          console.log("[feedback] User clicked", { value });
          plausible(`Feedback: ${value}`);

          /* Disable form and show note, if given */
          feedback.firstElementChild.disabled = true;
          var note = feedback.querySelector(".md-feedback__note [data-md-value='" + value + "']");
          if (note) note.hidden = false;
        })

        /* Show feedback */
        feedback.hidden = false;
      }
    });
  });
</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="The Algorithm - Biaslyze" >
      
        <meta  property="og:description"  content="The NLP Bias Identification Toolkit" >
      
        <meta  property="og:image"  content="https://biaslyze.org/assets/images/social/algorithm.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://biaslyze.org/algorithm/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="The Algorithm - Biaslyze" >
      
        <meta  name="twitter:description"  content="The NLP Bias Identification Toolkit" >
      
        <meta  name="twitter:image"  content="https://biaslyze.org/assets/images/social/algorithm.png" >
      
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#preparing-the-dataset" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Biaslyze" class="md-header__button md-logo" aria-label="Biaslyze" data-md-component="logo">
      
  <img src="../resources/biaslyze_logo_favicon.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Biaslyze
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              The Algorithm
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/biaslyze-dev/biaslyze" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    biaslyze
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
    
  
  The Algorithm

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../faq/" class="md-tabs__link">
        
  
    
  
  FAQ

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../tutorials/tutorial-toxic-comments/" class="md-tabs__link">
          
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../api/" class="md-tabs__link">
          
  
  API

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Biaslyze" class="md-nav__button md-logo" aria-label="Biaslyze" data-md-component="logo">
      
  <img src="../resources/biaslyze_logo_favicon.svg" alt="logo">

    </a>
    Biaslyze
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/biaslyze-dev/biaslyze" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    biaslyze
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    The Algorithm
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    The Algorithm
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#preparing-the-dataset" class="md-nav__link">
    Preparing the Dataset
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#identifying-keywords" class="md-nav__link">
    Identifying Keywords
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generating-counterfactual-examples" class="md-nav__link">
    Generating Counterfactual Examples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluating-model-outcomes" class="md-nav__link">
    Evaluating Model Outcomes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#calculating-counterfactual-scores" class="md-nav__link">
    Calculating Counterfactual Scores
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#analyzing-results" class="md-nav__link">
    Analyzing Results
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    Conclusion
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/tutorial-toxic-comments/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How to identify bias in hate speech detection
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/tutorial-working-with-custom-concepts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How to work with custom concepts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/tutorial-counterfactual-mitigation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How to use counterfactual texts for bias mitigation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/tutorial-hugging-hatexplain/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How to use biaslyze to test pretrained hate speech detection models
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../api/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Bias detectors
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            Bias detectors
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../biaslyze/bias_detectors/counterfactual_biasdetector/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CounterfactualBiasDetector
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Results
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            Results
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../biaslyze/results/counterfactual_detection_results/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CounterfactualDetectionResult
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Concepts
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            Concepts
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../biaslyze/concept_class/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Concept
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../biaslyze/concept_detectors/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Concept detectors
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../biaslyze/text_representation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TextRepresentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../biaslyze/utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>The Algorithm</h1>

<p>The main algorithm we use implemented in the <a href="../biaslyze/bias_detectors/counterfactual_biasdetector/">CounterfactualBiasDetector</a>, is an algorithm designed to detect bias by interchanging keywords associated with a protected concept and measuring the difference in outcomes for the model. The algorithm calculates a so called counterfactual score for each keyword, providing insights into potential biases in NLP ML applications. Here we outline the steps and processes involved in implementing the algorithm.</p>
<h2 id="preparing-the-dataset">Preparing the Dataset</h2>
<p>Before applying the bias detection algorithm, you need to gather a dataset that reflects the real-world context in which your NLP ML model operates. Ensure that the dataset includes a diverse representation of examples and accounts for different perspectives related to the protected concept you aim to investigate.</p>
<h2 id="identifying-keywords">Identifying Keywords</h2>
<p>Identify a set of keywords associated with the protected concept you want to examine for bias. These keywords should represent important terms or phrases that could influence the model's predictions or outcomes. For example, if you are analyzing bias related to gender, keywords might include "he," "she," "doctor," "nurse," and so on. We provide precompiled list of keywords for different concepts like gender or religion.</p>
<h2 id="generating-counterfactual-examples">Generating Counterfactual Examples</h2>
<p>For each keyword identified in the previous step, generate counterfactual examples by replacing the original keyword with a different keyword within the same category. This replacement helps simulate different scenarios and evaluate the model's sensitivity to changes in input while maintaining the context. For instance, if the original keyword is "he," you might replace it with "she" as a counterfactual example.</p>
<h2 id="evaluating-model-outcomes">Evaluating Model Outcomes</h2>
<p>Apply the NLP ML model to the original and counterfactual examples generated in the previous step. Record and compare the outcomes or predictions made by the model for each example. These outcomes could be classification labels, sentiment scores, or any other relevant outputs depending on the specific application.</p>
<h2 id="calculating-counterfactual-scores">Calculating Counterfactual Scores</h2>
<p>Based on the differences observed in the model outcomes between the original and counterfactual examples, calculate a counterfactual score for each keyword. The counterfactual score represents the magnitude of the bias associated with a particular keyword. You can determine the score by measuring the degree of change in the model's outputs, such as the difference in predicted probabilities or the change in classification labels.</p>
<div class="language-text highlight"><pre><span></span><code>+------------------------+               +------------------------+
| Original   Text        |               | Counterfactual Text    |
+------------------------+               +------------------------+
               |                                    |
               |                                    |
               V                                    V
    +----------------+                     +------------------------+
    | NLP ML Model   |                     | NLP ML Model           |
    +----------------+                     +------------------------+
               |                                    |
               |                                    |
               V                                    V
     +--------------+                       +----------------------+
     | Outcome      |                       | Outcome              |
     | (Original)   |                       | (Counterfactual)     |
     +--------------+                       +----------------------+
               |                                    |
               |                                    |
               V                                    V
               +------------------------------------+
               |      Counterfactual Score          |
               +------------------------------------+
</code></pre></div>
<h2 id="analyzing-results">Analyzing Results</h2>
<p>Analyze the counterfactual scores obtained for each keyword to gain insights into potential bias in the NLP ML application. Higher counterfactual scores indicate that the model is more sensitive to changes in that keyword, suggesting a higher degree of bias associated with it. By identifying specific keywords with significant counterfactual scores, you can focus on addressing and mitigating potential biases in your model.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The algorithm described above provides a systematic approach for detecting bias in NLP ML applications. By interchanging keywords associated with a protected concept and measuring the resulting differences in model outcomes, the algorithm enables the calculation of counterfactual scores. These scores help identify specific keywords that may contribute to biases in the application. By integrating this algorithm into your bias detection pipeline and quality management process, you can enhance the fairness and inclusiveness of your NLP ML models.</p>


  




                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Biaslyze
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": ["content.code.copy", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "toc.integrate"], "search": "../assets/javascripts/workers/search.dfff1995.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.dff1b7c8.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>